# -*- coding: utf-8 -*-
"""spam_detector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UvWtf4xxXiDYAEJWHswZ91SNAT2xCGns

# Spam Detector
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

"""## Retrieve the Data

The data is located at [https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv](https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv)

Dataset Source: [UCI Machine Learning Library](https://archive.ics.uci.edu/dataset/94/spambase)

Import the data using Pandas. Display the resulting DataFrame to confirm the import was successful.
"""

# Import the data
data = pd.read_csv("https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv")
data.head()

"""## Predict Model Performance

You will be creating and comparing two models on this data: a Logistic Regression, and a Random Forests Classifier. Before you create, fit, and score the models, make a prediction as to which model you think will perform better. You do not need to be correct!

Write down your prediction in the designated cells in your Jupyter Notebook, and provide justification for your educated guess.

*Replace the text in this markdown cell with your predictions, and be sure to provide justification for your guess.*

## Split the Data into Training and Testing Sets
"""

# Create the labels set `y` and features DataFrame `X`
X = data.drop(columns=["spam"])
y = data["spam"]

# Check the balance of the labels variable (`y`) by using the `value_counts` function.
print(y.value_counts())

# Split the data into X_train, X_test, y_train, y_test
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)
print(f"Training Set Size: {X_train.shape}")
print(f"Testing Set Size: {X_test.shape}")

"""## Scale the Features

Use the `StandardScaler` to scale the features data. Remember that only `X_train` and `X_test` DataFrames should be scaled.
"""

from sklearn.preprocessing import StandardScaler

# Create the StandardScaler instance
scaler = StandardScaler()

# Fit the Standard Scaler with the training data
scaler.fit(X_train)

# Scale the training data
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

"""## Create and Fit a Logistic Regression Model

Create a Logistic Regression model, fit it to the training data, make predictions with the testing data, and print the model's accuracy score. Use a `random_state` of `1`.
"""

# Create and fit a Logistic Regression model
from sklearn.linear_model import LogisticRegression
logistic_model = LogisticRegression(random_state=1)
logistic_model.fit(X_train, y_train)

# Make and save testing predictions with the trained Logistic Regression model using the test data
logistic_predictions = logistic_model.predict(X_test)
# Review the predictions
print(logistic_predictions)

# Calculate the accuracy score by evaluating `y_test` vs. `testing_predictions`.
logistic_accuracy = accuracy_score(y_test, logistic_predictions)
print(f"Logistic Regression Accuracy: {logistic_accuracy:.7f}")

"""## Create and Fit a Random Forest Classifier Model

Create a Random Forest Classifier model, fit it to the training data, make predictions with the testing data, and print the model's accuracy score. Use a `random_state` of `1`.
"""

# Create and fit a Random Forest Classifier model
from sklearn.ensemble import RandomForestClassifier
model_rf = RandomForestClassifier(random_state=1)
model_rf.fit(X_train, y_train)

# Make and save testing predictions with the trained Random Forest Classifier model using the test data
testing_predictions_rf = model_rf.predict(X_test)

# Review the predictions
print(testing_predictions_rf)

# Calculate the accuracy score by evaluating `y_test` vs. `testing_predictions`.
acc_score_rf = accuracy_score(y_test, testing_predictions_rf)
print(f"Accuracy score of Random Forest Classifier model: {acc_score_rf}")

"""## Evaluate the Models

Which model performed better? How does that compare to your prediction? Write down your results and thoughts in the following markdown cell.

## Model Comparison and Evaluation

The **Random Forest** model outperformed the **Logistic Regression** model based on accuracy.

- **Logistic Regression Accuracy**: 92.7%
- **Random Forest Accuracy**: 96.6%

### Observations:
- The higher accuracy of Random Forest aligns with the initial prediction that it would perform better.
- Random Forest leverages ensemble learning to combine multiple decision trees, capturing complex patterns effectively.
- Logistic Regression, as a linear model, is less capable of handling non-linear relationships in the data.

### Conclusion:
For this dataset, Random Forest is the better choice due to its superior accuracy. However, further evaluation with metrics such as precision, recall, and F1-score is recommended to ensure the model meets other performance criteria.
"""